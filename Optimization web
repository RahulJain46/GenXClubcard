Best Practices for Speeding Up Your Web Site

Combined files are a way to reduce the number of HTTP requests by combining all scripts into a single script, and similarly combining all CSS into a single stylesheet. Combining files is more challenging when the scripts and stylesheets vary from page to page, but making this part of your release process improves response times.

CSS Sprites are the preferred method for reducing the number of image requests. Combine your background images into a single image and use the CSS background-image and background-position properties to display the desired image segment.

Caching static content at the edge, like images and scripts, is only the beginning in terms of offloading requests from the origin and giving users the best experience. Dynamic content has long been thought of as a web resource that can serve different content for the same URI (Uniform Resource Indicator). A common misconception is that this content is always non-cacheable. When you break it down further, you realize that often times there are specific conditions that need to be met to produce different content, and that these conditions can be predefined. Caching more content not only reduces page load times, providing a more responsive site for its users, but also frees up computing cycles at you origin infrastructure to service transactional requests such as inventory checks, adds to the cart, and check-out more effectively.

Dynamic Page Caching (DPC) enables the caching of HTML pages based on request path, query strings, cookies, and request headers. Using any combination of attributes from an HTTP Request, Akamai will decide when and how to cache the responses and serve them. These attributes define the conditions that need to be met in order to serve "dynamic" pages from cache, while other requests that must go to the origin, will continue to do so.
A common use case is that of the anonymous user. In the example of an e-Commerce store, users who are not logged-in often see the same content and represent a large portion of hits to the site. Depending on the site design, these users' empty shopping cart and "Log In / Register" message in the header may be the same for all anonymous users. In this case, understanding if the user is anonymous based on attributes of the HTTP request will allow those users be served cached content. 

Asynchronous Javascript and XML (Ajax) – Utilize Ajax to dynamically create multiple page components, which also allows for caching responses in various types of storage including sessionStorage and localStorage. Cacheable Ajax is another method in reducing the number of requests sent to origin servers.

Add an Expires or a Cache-Control Header:

There are two aspects to this rule:

For static components: implement "Never expire" policy by setting far future Expires header
For dynamic components: use an appropriate Cache-Control header to help the browser with conditional requests
A first-time visitor to your page may have to make several HTTP requests, but by using the Expires header you make those components cacheable. This avoids unnecessary HTTP requests on subsequent page views. Expires headers are most often used with images, but they should be used on all components including scripts, stylesheets, and Flash components.
Browsers (and proxies) use a cache to reduce the number and size of HTTP requests, making web pages load faster. A web server uses the Expires header in the HTTP response to tell the client how long a component can be cached. 

Gzip Components:
The time it takes to transfer an HTTP request and response across the network can be significantly reduced by decisions made by front-end engineers
Compression reduces response times by reducing the size of the HTTP response.
web clients indicate support for compression with the Accept-Encoding header in the HTTP request.
If the web server sees this header in the request, it may compress the response using one of the methods listed by the client. The web server notifies the web client of this via the Content-Encoding header in the response
Servers choose what to gzip based on file type, but are typically too limited in what they decide to compress. Most web sites gzip their HTML documents. It's also worthwhile to gzip your scripts and stylesheets, but many web sites miss this opportunity. In fact, it's worthwhile to compress any text response including XML and JSON. Image and PDF files should not be gzipped because they are already compressed. Trying to gzip them not only wastes CPU but can potentially increase file sizes.

Put Stylesheets at the Top :
moving stylesheets to the document HEAD makes pages appear to be loading faster.

Put Scripts at the Bottom:
Avoid CSS Expressions:

Make JavaScript and CSS External:
Using external files in the real world generally produces faster pages because the JavaScript and CSS files are cached by the browser. JavaScript and CSS that are inlined in HTML documents get downloaded every time the HTML document is requested.
 The only exception where inlining is preferable is with home pages, 
 
 Reduce DNS Lookups:
 The Domain Name System (DNS) maps hostnames to IP addresses
 DNS lookups are cached for better performance. This caching can occur on a special caching server, maintained by the user's ISP or local area network, but there is also caching that occurs on the individual user's computer. The DNS information remains in the operating system's DNS cache (the "DNS Client service" on Microsoft Windows). Most browsers have their own caches, separate from the operating system's cache. As long as the browser keeps a DNS record in its own cache, it doesn't bother the operating system with a request for the record.
 When the client's DNS cache is empty (for both the browser and the operating system), the number of DNS lookups is equal to the number of unique hostnames in the web page. This includes the hostnames used in the page's URL, images, script files, stylesheets, Flash objects, etc. Reducing the number of unique hostnames reduces the number of DNS lookups.
 Reducing the number of unique hostnames has the potential to reduce the amount of parallel downloading that takes place in the page. Avoiding DNS lookups cuts response times, but reducing parallel downloads may increase response times. My guideline is to split these components across at least two but no more than four hostnames. This results in a good compromise between reducing DNS lookups and allowing a high degree of parallel downloads.
 
 Minify JavaScript and CSS:
 Minification is the practice of removing unnecessary characters from code to reduce its size thereby improving load times. When code is minified all comments are removed, as well as unneeded white space characters (space, newline, and tab). In the case of JavaScript, this improves response time performance because the size of the downloaded file is reduced.
 
 Avoid Redirects:
 Remove Duplicate Scripts:
 
 
 
Avoid Empty Image src:
cause the same effect: browser makes another request to your server.

Make favicon.ico Small and Cacheable:

When I use the term “favicon” I’m referring to an icon that is associated with a particular website,
Optimize CSS Sprites:
Arranging the images in the sprite horizontally as opposed to vertically usually results in a smaller file size.
"Be mobile-friendly" and don't leave big gaps between the images in a sprite. This doesn't affect the file size as much but requires less memory for the user agent to decompress the image into a pixel map.

Use GET for AJAX Requests:
Post-load Components:
Minimize the Number of iframes:
No 404s:
Reduce Cookie Size:

 Use Cookie-free Domains for Components:
 



Image optimization and rendering :
The srcset attribute, in fact, allows us to specify a list of sources for an image, which will be delivered based on the pixel density or size of the user’s screen
The srcset attribute includes a series of comma-separated values which, on one hand, specify an image URL and, on the other hand, the conditions under which the image will be shown. Among these conditions we can find pixel density, viewport width, or both of them.

Vector images are ideal for images that consist of geometric shapes
Vector images are zoom and resolution-independent
Raster images should be used for complex scenes with lots of irregular shapes and details.

Vector graphics use lines, points, and polygons to represent an image.
Raster graphics represent an image by encoding the individual values of each pixel within a rectangular grid.


SVG is an XML-based image format
SVG files should be minified to reduce their size
SVG files should be compressed with GZIP

A raster image is a grid of pixels
Each pixel encodes color and transparency information
Image compressors use a variety of techniques to reduce the number of required bits per pixel to reduce file size of the image

Image is processed with a "lossy" filter that eliminates some pixel data
Image is processed with a "lossless" filter that compresses the pixel data


HTTP cache:

When the server returns a response, it also emits a collection of HTTP headers, describing its content-type, length, caching directives, validation token, and more. For example, in the above exchange, the server returns a 1024-byte response, instructs the client to cache it for up to 120 seconds, and provides a validation token ("x234dff") that can be used after the response has expired to check if the resource has been modified.
Validating cached responses with ETags:
The server uses the ETag HTTP header to communicate a validation token.
The validation token enables efficient resource update checks: no data is transferred if the resource has not changed.
Assume that 120 seconds have passed since the initial fetch and the browser has initiated a new request for the same resource. First, the browser checks the local cache and finds the previous response. Unfortunately, the browser can't use the previous response because the response has now expired. At this point, the browser could dispatch a new request and fetch the new full response. However, that’s inefficient because if the resource hasn't changed, then there's no reason to download the same information that's already in cache!
 The server generates and returns an arbitrary token, which is typically a hash or some other fingerprint of the contents of the file. The client doesn't need to know how the fingerprint is generated; it only needs to send it to the server on the next request. If the fingerprint is still the same, then the resource hasn't changed and you can skip the download.

Cache-Control:

Each resource can define its caching policy via the Cache-Control HTTP header.
Cache-Control directives control who can cache the response, under which conditions, and for how long.

"no-cache"  : subsequent request to the same URL without first checking with the server if the response has changed. As a result, if a proper validation token (ETag) is present, no-cache incurs a roundtrip to validate the cached response, but can eliminate the download if the resource has not changed.


"no-store" : containing preivate data .

Invalidating and updating cached responses : versioning of the file 
